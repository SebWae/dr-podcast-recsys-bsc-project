{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from config import (\n",
    "    TRANSFORMED_DATA_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to view entire pandas outputs \n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# line of code to cancel the above display setting\n",
    "# pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'prd_number', 'series_title', 'unique_title', 'platform',\n",
       "       'device_type', 'pub_date', 'episode_duration', 'genre',\n",
       "       'branding_channel', 'mother_channel', 'category', 'content_time_spent',\n",
       "       'date', 'time', 'completion_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading transformed data\n",
    "transformed_df = pd.read_parquet(\"../\" + TRANSFORMED_DATA_PATH)\n",
    "transformed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 142344\n",
      "Number of unique shows: 538\n",
      "Number of unique episodes: 11918\n"
     ]
    }
   ],
   "source": [
    "# unique users\n",
    "n_users = len(transformed_df[\"user_id\"].unique())\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "\n",
    "# unique shows\n",
    "n_shows = len(transformed_df[\"series_title\"].unique())\n",
    "print(f\"Number of unique shows: {n_shows}\")\n",
    "\n",
    "# unique episodes\n",
    "n_episodes = len(transformed_df[\"prd_number\"].unique())\n",
    "print(f\"Number of unique episodes: {n_episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold for number of plays per episode\n",
    "Checking how many unique episodes and interactions will be filtered away for different thresholds.\n",
    "\n",
    "NB! The results below cannot be reproduced since it was performed before applying the filter to `01_filter.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prd_number\n",
      "19388840413    1\n",
      "13332195418    1\n",
      "14202412454    1\n",
      "14202412456    1\n",
      "14202410465    1\n",
      "13332195424    1\n",
      "13332195425    1\n",
      "13332195426    1\n",
      "13332195427    1\n",
      "14202410481    1\n",
      "Name: user_id, dtype: int64\n",
      "Number of unique episodes: 22596\n",
      "   threshold  episode%  interaction%\n",
      "0          5  0.648212      0.995035\n",
      "1         10  0.527438      0.988822\n",
      "2         20  0.382767      0.973514\n",
      "3         50  0.210878      0.932505\n"
     ]
    }
   ],
   "source": [
    "# loading filtered data\n",
    "df = pd.read_parquet('../data/podcast_data_filtered.parquet')\n",
    "\n",
    "# total number of interactions\n",
    "n_interactions = len(df)\n",
    "\n",
    "# grouping by prd_number and counting the number of appearances\n",
    "prd_grp_df = df.groupby('prd_number')['user_id'].count().sort_values(ascending=True)\n",
    "print(prd_grp_df.head(10))\n",
    "n_episodes = len(prd_grp_df)\n",
    "print(f\"Number of unique episodes: {n_episodes}\")\n",
    "\n",
    "# testing different thresholds\n",
    "thresholds = [5, 10, 20, 50]\n",
    "\n",
    "episode_threshold_data = {\"threshold\": thresholds,\n",
    "                          \"episode%\": [],\n",
    "                          \"interaction%\": [],\n",
    "                          }\n",
    "\n",
    "# testing the thresholds\n",
    "for threshold in thresholds:\n",
    "    # filtering the DataFrame based on the threshold\n",
    "    filtered_df = df[df['prd_number'].isin(prd_grp_df[prd_grp_df >= threshold].index)]\n",
    "\n",
    "    # calculating the percentage of episodes and interactions\n",
    "    episode_percentage = len(filtered_df['prd_number'].unique()) / n_episodes\n",
    "    interaction_percentage = len(filtered_df) / n_interactions\n",
    "\n",
    "    # appending the results to the data dictionary\n",
    "    episode_threshold_data[\"episode%\"].append(episode_percentage)\n",
    "    episode_threshold_data[\"interaction%\"].append(interaction_percentage)\n",
    "\n",
    "# generating a dataframe from the gathered data on episodes\n",
    "episode_threshold_df = pd.DataFrame(episode_threshold_data)\n",
    "print(episode_threshold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be reasonable to filter away episodes with less than 10 plays, as this will keep more than half of the episodes (52.7%) in the training data, while still keeping 98.9% of the interactions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
