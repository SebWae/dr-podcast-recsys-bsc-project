{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from config import (\n",
    "    TRANSFORMED_DATA_PATH,\n",
    "    METADATA_PATH,\n",
    "    TRAIN_DATA_PATH,\n",
    "    TEST_DATA_PATH,\n",
    "    METADATA_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to view entire pandas outputs \n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# line of code to cancel the above display setting\n",
    "# pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading transformed data\n",
    "transformed_df = pd.read_parquet(\"../\" + TRANSFORMED_DATA_PATH)\n",
    "\n",
    "# loading train data\n",
    "train_df = pd.read_parquet(\"../\" + TRAIN_DATA_PATH)\n",
    "\n",
    "# loading test data\n",
    "test_df = pd.read_parquet(\"../\" + TEST_DATA_PATH)\n",
    "\n",
    "# loading metadata\n",
    "meta_df = pd.read_parquet(\"../\" + METADATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics for transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 44007\n",
      "Number of unique shows: 595\n",
      "Number of unique episodes: 21056\n"
     ]
    }
   ],
   "source": [
    "# unique users\n",
    "n_users = len(transformed_df[\"user_id\"].unique())\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "\n",
    "# unique shows\n",
    "n_shows = len(transformed_df[\"series_title\"].unique())\n",
    "print(f\"Number of unique shows: {n_shows}\")\n",
    "\n",
    "# unique episodes\n",
    "n_episodes = len(transformed_df[\"prd_number\"].unique())\n",
    "print(f\"Number of unique episodes: {n_episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity of the user-show matrix for the CF recommender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining metadata onto the train data\n",
    "train_w_meta = pd.merge(train_df, meta_df, on=\"prd_number\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44007\n",
      "575\n",
      "352721\n",
      "The sparsity of the user-show matrix is 0.9861\n"
     ]
    }
   ],
   "source": [
    "# grouping by user_id and series_title\n",
    "grouped_df = train_w_meta.groupby([\"user_id\", \"series_title\"]).agg(\n",
    "    avg_completion_rate =   (\"completion_rate\", \"mean\"),\n",
    "    n_episodes =            (\"prd_number\", \"count\")\n",
    "    ).reset_index()\n",
    "\n",
    "# number of users\n",
    "n_users = len(grouped_df[\"user_id\"].unique())\n",
    "print(n_users_train)\n",
    "# number of podcast shows\n",
    "n_shows = len(grouped_df[\"series_title\"].unique())\n",
    "print(n_episodes_train)\n",
    "# number of interactions in train data\n",
    "n_interactions = len(grouped_df)\n",
    "print(n_interactions)\n",
    "# sparsity of the training interaction matrix\n",
    "interaction_matrix_sparsity_train = 1 - (n_interactions / (n_users * n_shows))\n",
    "print(f\"The sparsity of the user-show matrix is {interaction_matrix_sparsity_train:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Episodes in Test Data\n",
    "Assessing how many of the episodes in the test data have been published after 2024-11-11 (the split date).  \n",
    "\n",
    "This may be the reason why the CF recommender is performing badly - it is only able to recommend episodes from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.31% of the test interactions involve episodes published after the split date (2024-11-11).\n"
     ]
    }
   ],
   "source": [
    "# import test data\n",
    "test_df = pd.read_parquet(\"../\" + TEST_DATA_PATH)\n",
    "\n",
    "# importing metadata\n",
    "meta_df = pd.read_parquet(\"../\" + METADATA_PATH)\n",
    "\n",
    "# joining metadata onto the test data\n",
    "test_w_meta_df = pd.merge(test_df, meta_df, on=\"prd_number\", how=\"left\")\n",
    "\n",
    "# filtering on pub_date\n",
    "test_df_filtered = test_w_meta_df[test_w_meta_df[\"pub_date\"] >= \"2024-11-11\"]\n",
    "\n",
    "# computing proportion with new episodes among test data\n",
    "perc_new = len(test_df_filtered) / len(test_df) * 100\n",
    "print(f\"{perc_new:.2f}% of the test interactions involve episodes published after the split date (2024-11-11).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold for number of plays per episode\n",
    "Checking how many unique episodes and interactions will be filtered away for different thresholds.\n",
    "\n",
    "NB! The results below cannot be reproduced since it was performed before applying the filter to `01_filter.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prd_number\n",
      "19388840413    1\n",
      "13332195418    1\n",
      "14202412454    1\n",
      "14202412456    1\n",
      "14202410465    1\n",
      "13332195424    1\n",
      "13332195425    1\n",
      "13332195426    1\n",
      "13332195427    1\n",
      "14202410481    1\n",
      "Name: user_id, dtype: int64\n",
      "Number of unique episodes: 22596\n",
      "   threshold  episode%  interaction%\n",
      "0          5  0.648212      0.995035\n",
      "1         10  0.527438      0.988822\n",
      "2         20  0.382767      0.973514\n",
      "3         50  0.210878      0.932505\n"
     ]
    }
   ],
   "source": [
    "# loading filtered data\n",
    "df = pd.read_parquet('../data/podcast_data_filtered.parquet')\n",
    "\n",
    "# total number of interactions\n",
    "n_interactions = len(df)\n",
    "\n",
    "# grouping by prd_number and counting the number of appearances\n",
    "prd_grp_df = df.groupby('prd_number')['user_id'].count().sort_values(ascending=True)\n",
    "print(prd_grp_df.head(10))\n",
    "n_episodes = len(prd_grp_df)\n",
    "print(f\"Number of unique episodes: {n_episodes}\")\n",
    "\n",
    "# testing different thresholds\n",
    "thresholds = [5, 10, 20, 50]\n",
    "\n",
    "episode_threshold_data = {\"threshold\": thresholds,\n",
    "                          \"episode%\": [],\n",
    "                          \"interaction%\": [],\n",
    "                          }\n",
    "\n",
    "# testing the thresholds\n",
    "for threshold in thresholds:\n",
    "    # filtering the DataFrame based on the threshold\n",
    "    filtered_df = df[df['prd_number'].isin(prd_grp_df[prd_grp_df >= threshold].index)]\n",
    "\n",
    "    # calculating the percentage of episodes and interactions\n",
    "    episode_percentage = len(filtered_df['prd_number'].unique()) / n_episodes\n",
    "    interaction_percentage = len(filtered_df) / n_interactions\n",
    "\n",
    "    # appending the results to the data dictionary\n",
    "    episode_threshold_data[\"episode%\"].append(episode_percentage)\n",
    "    episode_threshold_data[\"interaction%\"].append(interaction_percentage)\n",
    "\n",
    "# generating a dataframe from the gathered data on episodes\n",
    "episode_threshold_df = pd.DataFrame(episode_threshold_data)\n",
    "print(episode_threshold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be reasonable to filter away episodes with less than 10 plays, as this will keep more than half of the episodes (52.7%) in the training data, while still keeping 98.9% of the interactions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr-podcast-recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
