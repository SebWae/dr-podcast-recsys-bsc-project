{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from config import (\n",
    "    TRANSFORMED_DATA_PATH,\n",
    "    SPLIT_DATE_TRAIN_VAL,\n",
    "    SPLIT_DATE_VAL_TEST,\n",
    "    MIN_PLAYS_PER_USER,\n",
    "    TRAIN_DATA_PATH,\n",
    "    VAL_DATA_PATH,\n",
    "    TEST_DATA_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to investigate different train-test split strategies.  \n",
    "\n",
    "NB! The notebook was written before including the global user split in the filtering script why the summary statistics are not accurate for the currently used data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prd_number",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "series_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unique_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "device_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pub_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "episode_duration",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "branding_channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mother_channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content_time_spent",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "completion_rate",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "98e4ed5a-cc86-4c26-840f-65886b992c91",
       "rows": [
        [
         "0",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11032421443",
         "Brinkmanns briks",
         "Brinkmanns briks: Vi skal tale om pillerne_11032421443",
         "web",
         "PC",
         "2024-10-30",
         "3422",
         "Fakta og debat",
         "DR P1",
         "DR P1",
         "Oplysning og kultur",
         "3423",
         "2024-11-01",
         "08:56:00",
         "1.0"
        ],
        [
         "1",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11032422442",
         "Hjernekassen på P1",
         "Hjernekassen på P1: Forebyggelse_11032422442",
         "web",
         "PC",
         "2024-10-29",
         "3363",
         "Fakta og debat",
         "DR P1",
         "DR P1",
         "Oplysning og kultur",
         "359",
         "2024-11-01",
         "11:19:00",
         "0.10674992566161165"
        ],
        [
         "2",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11162405447",
         "Ubegribeligt",
         "Ubegribeligt: Vand_11162405447",
         "web",
         "PC",
         "2024-10-31",
         "3417",
         "Fakta og debat",
         "DR P1",
         "DR P1",
         "Aktualitet og debat",
         "5160",
         "2024-11-01",
         "09:53:00",
         "1.0"
        ],
        [
         "3",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11802437044",
         "Stjerner og striber",
         "Stjerner og striber: Joken, der ikke vil dø_11802437044",
         "web",
         "PC",
         "2024-11-01",
         "2847",
         "Aktualitet",
         "DR P1",
         "-",
         "Nyheder",
         "2847",
         "2024-11-01",
         "08:40:00",
         "1.0"
        ],
        [
         "4",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11802451178",
         "Tiden",
         "Tiden: Skraldemanden Trump, spansk oversvømmelse og ben-erstatninger_11802451178",
         "web",
         "PC",
         "2024-11-01",
         "947",
         "Nyheder",
         "DR Lyd",
         "-",
         "Nyheder",
         "610",
         "2024-11-01",
         "09:27:00",
         "0.6441393875395988"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prd_number</th>\n",
       "      <th>series_title</th>\n",
       "      <th>unique_title</th>\n",
       "      <th>platform</th>\n",
       "      <th>device_type</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>episode_duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>branding_channel</th>\n",
       "      <th>mother_channel</th>\n",
       "      <th>category</th>\n",
       "      <th>content_time_spent</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>completion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11032421443</td>\n",
       "      <td>Brinkmanns briks</td>\n",
       "      <td>Brinkmanns briks: Vi skal tale om pillerne_110...</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>3422</td>\n",
       "      <td>Fakta og debat</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>Oplysning og kultur</td>\n",
       "      <td>3423</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11032422442</td>\n",
       "      <td>Hjernekassen på P1</td>\n",
       "      <td>Hjernekassen på P1: Forebyggelse_11032422442</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-10-29</td>\n",
       "      <td>3363</td>\n",
       "      <td>Fakta og debat</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>Oplysning og kultur</td>\n",
       "      <td>359</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>11:19:00</td>\n",
       "      <td>0.106750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11162405447</td>\n",
       "      <td>Ubegribeligt</td>\n",
       "      <td>Ubegribeligt: Vand_11162405447</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>3417</td>\n",
       "      <td>Fakta og debat</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>Aktualitet og debat</td>\n",
       "      <td>5160</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>09:53:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11802437044</td>\n",
       "      <td>Stjerner og striber</td>\n",
       "      <td>Stjerner og striber: Joken, der ikke vil dø_11...</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>2847</td>\n",
       "      <td>Aktualitet</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>-</td>\n",
       "      <td>Nyheder</td>\n",
       "      <td>2847</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>08:40:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11802451178</td>\n",
       "      <td>Tiden</td>\n",
       "      <td>Tiden: Skraldemanden Trump, spansk oversvømmel...</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>947</td>\n",
       "      <td>Nyheder</td>\n",
       "      <td>DR Lyd</td>\n",
       "      <td>-</td>\n",
       "      <td>Nyheder</td>\n",
       "      <td>610</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>09:27:00</td>\n",
       "      <td>0.644139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_id   prd_number  \\\n",
       "0  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11032421443   \n",
       "1  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11032422442   \n",
       "2  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11162405447   \n",
       "3  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11802437044   \n",
       "4  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11802451178   \n",
       "\n",
       "          series_title                                       unique_title  \\\n",
       "0     Brinkmanns briks  Brinkmanns briks: Vi skal tale om pillerne_110...   \n",
       "1   Hjernekassen på P1       Hjernekassen på P1: Forebyggelse_11032422442   \n",
       "2         Ubegribeligt                     Ubegribeligt: Vand_11162405447   \n",
       "3  Stjerner og striber  Stjerner og striber: Joken, der ikke vil dø_11...   \n",
       "4                Tiden  Tiden: Skraldemanden Trump, spansk oversvømmel...   \n",
       "\n",
       "  platform device_type    pub_date  episode_duration           genre  \\\n",
       "0      web          PC  2024-10-30              3422  Fakta og debat   \n",
       "1      web          PC  2024-10-29              3363  Fakta og debat   \n",
       "2      web          PC  2024-10-31              3417  Fakta og debat   \n",
       "3      web          PC  2024-11-01              2847      Aktualitet   \n",
       "4      web          PC  2024-11-01               947         Nyheder   \n",
       "\n",
       "  branding_channel mother_channel             category  content_time_spent  \\\n",
       "0            DR P1          DR P1  Oplysning og kultur                3423   \n",
       "1            DR P1          DR P1  Oplysning og kultur                 359   \n",
       "2            DR P1          DR P1  Aktualitet og debat                5160   \n",
       "3            DR P1              -              Nyheder                2847   \n",
       "4           DR Lyd              -              Nyheder                 610   \n",
       "\n",
       "         date      time  completion_rate  \n",
       "0  2024-11-01  08:56:00         1.000000  \n",
       "1  2024-11-01  11:19:00         0.106750  \n",
       "2  2024-11-01  09:53:00         1.000000  \n",
       "3  2024-11-01  08:40:00         1.000000  \n",
       "4  2024-11-01  09:27:00         0.644139  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading transformed data\n",
    "df = pd.read_parquet(\"../\" + TRANSFORMED_DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 142344\n",
      "Number of interactions: 2951510\n"
     ]
    }
   ],
   "source": [
    "# grouping by prd_number and counting the number of plays for each episode\n",
    "prd_grp_df = df.groupby('prd_number')['user_id'].count().sort_values(ascending=True)\n",
    "\n",
    "# filtering away episodes with less than 5 interactions\n",
    "filtered_df = df[df['prd_number'].isin(prd_grp_df[prd_grp_df >= 10].index)]\n",
    "\n",
    "# number of unique users \n",
    "n_users = len(set(filtered_df['user_id']))\n",
    "\n",
    "# number of interactions (rows in the df)\n",
    "n_interactions = len(filtered_df)\n",
    "\n",
    "# printing the summary statistics\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of interactions: {n_interactions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal User Split\n",
    "\n",
    "This splitting strategy defines a training and test set of each user according to some splitting percentage, e.g., 80% training data and 20% testing data is being recommended in the literature.  \n",
    "\n",
    "Investigating the consequences of implementing a 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with at least 3 prd_numbers: 95395 (67.0% of users are kept)\n",
      "Number of interactions left: 2887658 (97.8% of interactions are kept)\n"
     ]
    }
   ],
   "source": [
    "# grouping by user_id and counting the number of prd_numbers for each user\n",
    "df_grouped = filtered_df.groupby('user_id')['prd_number'].count().reset_index()\n",
    "df_grouped.rename(columns={'prd_number': 'prd_count'}, inplace=True)\n",
    "\n",
    "# number of users with at least 3 prd_numbers\n",
    "df_grouped = df_grouped[df_grouped['prd_count'] >= 3]\n",
    "\n",
    "# number of users left\n",
    "users_set = set(df_grouped['user_id'])\n",
    "n_users_usplit = len(users_set)\n",
    "\n",
    "# number of interactions left (rows in the df_grouped)\n",
    "df_filtered = filtered_df[filtered_df['user_id'].isin(users_set)]\n",
    "n_interactions_usplit = len(df_filtered)\n",
    "\n",
    "# printing the results\n",
    "print(f\"Number of users with at least 3 prd_numbers: {n_users_usplit} ({n_users_usplit/n_users:.1%} of users are kept)\")\n",
    "print(f\"Number of interactions left: {n_interactions_usplit} ({n_interactions_usplit/n_interactions:.1%} of interactions are kept)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Global Split\n",
    "Define a single global timestamp that works as the boundary between train and test data for all users/interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make the cut on the `date` attribute, where the selected date is a Monday. In this way entire weeks are contained in the training and test data. This might be an appropriate decision since podcast listening and publication have weekly patterns. This must be investigated in the EDA and related work section about podcast listening patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    train%     test%    users%  interactions%\n",
      "0  2024-10-28  0.603096  0.396904  0.459640       0.880902\n",
      "1  2024-11-04  0.675683  0.324317  0.449313       0.873870\n",
      "2  2024-11-11  0.747187  0.252813  0.426621       0.858558\n",
      "3  2024-11-18  0.821092  0.178908  0.386992       0.825525\n"
     ]
    }
   ],
   "source": [
    "# testing size of train - and test data when splitting on different dates\n",
    "split_dates = ['2024-10-28', '2024-11-04', '2024-11-11', '2024-11-18']\n",
    "\n",
    "data = {'date': split_dates,\n",
    "        'train%': [],\n",
    "        'test%': [],\n",
    "        'users%': [],\n",
    "        'interactions%': [],\n",
    "        }\n",
    "\n",
    "for split_date in split_dates:\n",
    "    # splitting the data\n",
    "    train_df = filtered_df[filtered_df['date'] < split_date]\n",
    "    test_df = filtered_df[filtered_df['date'] >= split_date]\n",
    "\n",
    "    # number of unique users both in the train and test data\n",
    "    common_users = set(train_df['user_id']).intersection(set(test_df['user_id']))\n",
    "    n_common_users = len(common_users)\n",
    "\n",
    "    # filter df according to the common users\n",
    "    train_df_common = train_df[train_df['user_id'].isin(common_users)]\n",
    "    test_df_common = test_df[test_df['user_id'].isin(common_users)]\n",
    "\n",
    "    # computing train and test percentages\n",
    "    train_interactions = len(train_df_common)\n",
    "    test_interactions = len(test_df_common)\n",
    "    total_interactions = train_interactions + test_interactions\n",
    "    train_perc = train_interactions / total_interactions\n",
    "    test_perc = test_interactions / total_interactions\n",
    "    data[\"train%\"].append(train_perc)\n",
    "    data[\"test%\"].append(test_perc)\n",
    "\n",
    "     # computing the percentage of users\n",
    "    perc_users = n_common_users / n_users\n",
    "    data[\"users%\"].append(perc_users)\n",
    "\n",
    "    # computing the percentage of total interactions\n",
    "    perc_interactions = total_interactions / n_interactions\n",
    "    data[\"interactions%\"].append(perc_interactions)\n",
    "\n",
    "# generating a dataframe from the gathered data\n",
    "global_split_df = pd.DataFrame(data)\n",
    "print(global_split_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "November 11, 2024, seems like a reasonable global split date, as the balance between train and test data is close to 75-25 and more users are kept compared to November 18, 2024.\n",
    "\n",
    "Assessing number of episodes per user in the training set, as I might want to filter away users with less than x episodes for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold    train%     test%  users_total%  users_split%  interactions%\n",
      "0          2  0.998015  0.982172      0.400221      0.938116       0.994010\n",
      "1          3  0.994801  0.965374      0.378843      0.888007       0.987361\n",
      "2          4  0.990688  0.950548      0.360605      0.845258       0.980540\n",
      "3          5  0.985839  0.936243      0.344482      0.807466       0.973301\n"
     ]
    }
   ],
   "source": [
    "# applying global user split\n",
    "split_date = '2024-11-11'\n",
    "train_df = filtered_df[filtered_df['date'] < split_date]\n",
    "test_df = filtered_df[filtered_df['date'] >= split_date]\n",
    "\n",
    "# number of unique users both in the train and test data\n",
    "common_users = set(train_df['user_id']).intersection(set(test_df['user_id']))\n",
    "n_common_users = len(common_users)\n",
    "\n",
    "# filter df according to the common users\n",
    "train_df_common = train_df[train_df['user_id'].isin(common_users)]\n",
    "test_df_common = test_df[test_df['user_id'].isin(common_users)]\n",
    "\n",
    "# number of interactions\n",
    "n_interactions_train = len(train_df_common)\n",
    "n_interactions_test = len(test_df_common)\n",
    "n_interactions_org = n_interactions_train + n_interactions_test\n",
    "\n",
    "# grouping by user_id and counting the number of prd_numbers for each user in the train data\n",
    "df_grouped_train = train_df_common.groupby('user_id')['prd_number'].count().reset_index()\n",
    "\n",
    "# providing a name for the count column\n",
    "df_grouped_train.rename(columns={'prd_number': 'prd_count'}, inplace=True)\n",
    "\n",
    "# thresholds to test\n",
    "user_thresholds = [2, 3, 4, 5]\n",
    "\n",
    "data = {'threshold': user_thresholds,\n",
    "        'train%': [],\n",
    "        'test%': [],\n",
    "        'users_total%': [],\n",
    "        'users_split%': [],\n",
    "        'interactions%': [],\n",
    "        }\n",
    "\n",
    "for threshold in user_thresholds:\n",
    "    # filtering the train data according to the threshold\n",
    "    df_grouped_train_filtered = df_grouped_train[df_grouped_train['prd_count'] >= threshold]\n",
    "    users_set = set(df_grouped_train_filtered['user_id'])\n",
    "    \n",
    "    # filtering the train and test data according to the common users\n",
    "    train_df_common_filtered = train_df_common[train_df_common['user_id'].isin(users_set)]\n",
    "    test_df_common_filtered = test_df_common[test_df_common['user_id'].isin(users_set)]\n",
    "\n",
    "    # computing train and test percentages\n",
    "    train_interactions = len(train_df_common_filtered)\n",
    "    test_interactions = len(test_df_common_filtered)\n",
    "    total_interactions = train_interactions + test_interactions\n",
    "    train_perc = train_interactions / n_interactions_train\n",
    "    test_perc = test_interactions / n_interactions_test\n",
    "    data[\"train%\"].append(train_perc)\n",
    "    data[\"test%\"].append(test_perc)\n",
    "\n",
    "    # computing the percentage of users\n",
    "    perc_users = len(users_set) / n_users\n",
    "    perc_users_split = len(users_set) / n_common_users\n",
    "    data[\"users_total%\"].append(perc_users)\n",
    "    data[\"users_split%\"].append(perc_users_split)\n",
    "\n",
    "    # computing the percentage of total interactions\n",
    "    perc_interactions = total_interactions / n_interactions_org\n",
    "    data[\"interactions%\"].append(perc_interactions)\n",
    "    \n",
    "# generating a dataframe from the gathered data\n",
    "user_split_df = pd.DataFrame(data)\n",
    "print(user_split_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tran%` and `test%` indicate the percentages of the interactions in the original train and test sets before filtering on the number of plays per user.\n",
    "\n",
    "`user_total%` indicate the percentage of original users kept before applying any filtering. This was 42.2% for the global split using 2024-11-11 as the split date.\n",
    "\n",
    "`user_split%`indicate the percentage of users kept after applying the global split, but before filtering on the number of plays per user.\n",
    "\n",
    "`interactions%` indicate the percentage of interactions among both the train and test set before filtering on the number of plays per user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision\n",
    "The user split keeps a larger proportion of the users and interactions, but is a less realistic strategy to implement for the collaborative filtering algorithms. This is because some of the training data will be in the future compared to some of the testing data and vice versa.  \n",
    "\n",
    "The global split throws away more users and a few more interactions. However, it enforces a more realistic splitting strategy, why I'm favoring this strategy over the temporal user split.  \n",
    "\n",
    "For the global user split I'll use 2024-11-11 as the split date and filter on users with at least 2 plays in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Validation Set\n",
    "For parameter tuning and early stopping during training, I need a validation set. \n",
    "\n",
    "This will be defined using the global user split as for the test set. A period of 3 weeks will also be chosen for the validation set since it is desired for the recommender systems to perform well on interaction data covering 3 weeks (the duration of the test set).  \n",
    "\n",
    "Thus the \"2024-10-21\" will be chosen as the split date between the training and validation set.  \n",
    "\n",
    "Now it is required for a user to have interactions in 3 different time periods:\n",
    "- Training set: \"2024-09-02\" - \"2024-10-20\" ($\\geq2$ interactions)\n",
    "- Validation set: \"2024-10-21\" - \"2024-11-10\" ($\\geq1$ interactions)\n",
    "- Test set: \"2024-11-11\" - \"2024-12-01\" ($\\geq1$ interactions)\n",
    "\n",
    "Below I will assess how many users and interactions will be filtered away as a consequence of implementing the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# defining train set\n",
    "train_df = df[df[\"date\"] < SPLIT_DATE_TRAIN_VAL]\n",
    "train_interactions = len(train_df)\n",
    "\n",
    "# defining validation set\n",
    "validation_df = df[(df[\"date\"] >= SPLIT_DATE_TRAIN_VAL) & (df[\"date\"] < SPLIT_DATE_VAL_TEST)]\n",
    "validation_interactions = len(validation_df)\n",
    "\n",
    "# defining test set\n",
    "test_df = df[df[\"date\"] >= SPLIT_DATE_VAL_TEST]\n",
    "test_interactions = len(test_df)\n",
    "\n",
    "# total number of interactions \n",
    "total_interactions = len(df)\n",
    "\n",
    "# checking if the 3 sets are disjoint (should return True)\n",
    "print(train_interactions + validation_interactions + test_interactions == total_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering away users below threshold for number of plays per user\n",
    "df_train_grp = train_df.groupby('user_id')['prd_number'].count()\n",
    "train_df_filtered = train_df[train_df['user_id'].isin(df_train_grp[df_train_grp >= MIN_PLAYS_PER_USER].index)]\n",
    "\n",
    "# set of users in each set\n",
    "train_users = set(train_df_filtered[\"user_id\"])\n",
    "validation_users = set(validation_df[\"user_id\"])\n",
    "test_users = set(test_df[\"user_id\"])\n",
    "\n",
    "# set of common users\n",
    "common_users = train_users.intersection(validation_users, test_users)\n",
    "\n",
    "# making sure each set only contains the common users\n",
    "train_df_common = train_df_filtered[train_df_filtered['user_id'].isin(common_users)]\n",
    "validation_df_common = validation_df[validation_df['user_id'].isin(common_users)]\n",
    "test_df_common = test_df[test_df['user_id'].isin(common_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43782 out of 142344 are kept when implementing the validation set.\n",
      "This corresponds to 30.76%\n",
      "79.07% of the train interactions are kept.\n",
      "81.76% of the validation interactions are kept.\n",
      "77.38% of the test interactions are kept.\n",
      "79.30% of all interactions are kept.\n"
     ]
    }
   ],
   "source": [
    "# percentage of total users kept\n",
    "n_users_total = len(df[\"user_id\"].unique())\n",
    "n_users_common = len(common_users)\n",
    "perc_of_total_users = n_users_common / n_users_total * 100\n",
    "print(f\"{n_users_common} out of {n_users_total} are kept when implementing the validation set.\")\n",
    "print(f\"This corresponds to {perc_of_total_users:.2f}%\")\n",
    "\n",
    "# number of interactions (rows) in each set\n",
    "train_interactions_common = len(train_df_common)\n",
    "validation_interactions_common = len(validation_df_common)\n",
    "test_interactions_common = len(test_df_common)\n",
    "total_interactions_common = train_interactions_common + validation_interactions_common + test_interactions_common\n",
    "\n",
    "# percentage of interactions kept for each set\n",
    "train_interactions_perc = train_interactions_common / train_interactions * 100\n",
    "validation_interactions_perc = validation_interactions_common / validation_interactions * 100\n",
    "test_interactions_perc = test_interactions_common / test_interactions * 100\n",
    "total_interactions_perc = total_interactions_common / total_interactions * 100\n",
    "print(f\"{train_interactions_perc:.2f}% of the train interactions are kept.\")\n",
    "print(f\"{validation_interactions_perc:.2f}% of the validation interactions are kept.\")\n",
    "print(f\"{test_interactions_perc:.2f}% of the test interactions are kept.\")\n",
    "print(f\"{total_interactions_perc:.2f}% of all interactions are kept.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the proportion between the training, validation, and test data for various split dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_val_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_test_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_test_weeks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test%",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5dde50a2-4129-4056-80e5-34e2b0514acc",
       "rows": [
        [
         "0",
         "2024-09-23",
         "2024-10-28",
         "5",
         "21.88454833369688",
         "38.49672556091573",
         "39.618726105387395"
        ],
        [
         "1",
         "2024-10-07",
         "2024-11-04",
         "4",
         "36.95804355435163",
         "31.588234001072035",
         "31.453722444576336"
        ],
        [
         "2",
         "2024-10-21",
         "2024-11-11",
         "3",
         "51.91896672128292",
         "24.5725390134241",
         "23.508494265292974"
        ],
        [
         "3",
         "2024-11-04",
         "2024-11-18",
         "2",
         "68.54627755542366",
         "15.954837596952313",
         "15.498884847624023"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_val_date</th>\n",
       "      <th>val_test_date</th>\n",
       "      <th>val_test_weeks</th>\n",
       "      <th>train%</th>\n",
       "      <th>val%</th>\n",
       "      <th>test%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>5</td>\n",
       "      <td>21.884548</td>\n",
       "      <td>38.496726</td>\n",
       "      <td>39.618726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>4</td>\n",
       "      <td>36.958044</td>\n",
       "      <td>31.588234</td>\n",
       "      <td>31.453722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>3</td>\n",
       "      <td>51.918967</td>\n",
       "      <td>24.572539</td>\n",
       "      <td>23.508494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>2</td>\n",
       "      <td>68.546278</td>\n",
       "      <td>15.954838</td>\n",
       "      <td>15.498885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_val_date val_test_date  val_test_weeks     train%       val%  \\\n",
       "0     2024-09-23    2024-10-28               5  21.884548  38.496726   \n",
       "1     2024-10-07    2024-11-04               4  36.958044  31.588234   \n",
       "2     2024-10-21    2024-11-11               3  51.918967  24.572539   \n",
       "3     2024-11-04    2024-11-18               2  68.546278  15.954838   \n",
       "\n",
       "       test%  \n",
       "0  39.618726  \n",
       "1  31.453722  \n",
       "2  23.508494  \n",
       "3  15.498885  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split_dates = [\"2024-09-23\", \"2024-10-07\", \"2024-10-21\", \"2024-11-04\"]\n",
    "val_test_split_dates = ['2024-10-28', '2024-11-04', '2024-11-11', '2024-11-18']\n",
    "\n",
    "# data to store data\n",
    "data = {\"train_val_date\": train_val_split_dates,\n",
    "        \"val_test_date\": val_test_split_dates,\n",
    "        \"val_test_weeks\": [5, 4, 3, 2],\n",
    "        \"train%\": [],\n",
    "        \"val%\": [],\n",
    "        \"test%\": []}\n",
    "\n",
    "# loading the transformed data\n",
    "transformed_df = pd.read_parquet(\"../\" + TRANSFORMED_DATA_PATH)\n",
    "total_interactions = len(transformed_df)\n",
    "\n",
    "for date1, date2 in zip(train_val_split_dates, val_test_split_dates):\n",
    "    train_df = transformed_df[transformed_df[\"date\"] < date1]\n",
    "    val_df = transformed_df[(transformed_df[\"date\"] >= date1) & (transformed_df[\"date\"] < date2)]\n",
    "    test_df = transformed_df[transformed_df[\"date\"] >= date2]\n",
    "\n",
    "    # number of interactions in each of the three sets\n",
    "    train_interactions = len(train_df)\n",
    "    val_interactions = len(val_df)\n",
    "    test_interactions = len(test_df)\n",
    "\n",
    "    # proportions\n",
    "    train_perc = train_interactions / total_interactions * 100, 2\n",
    "    val_perc = val_interactions / total_interactions * 100\n",
    "    test_perc = test_interactions / total_interactions * 100\n",
    "\n",
    "    # saving to data dict\n",
    "    data[\"train%\"].append(train_perc)\n",
    "    data[\"val%\"].append(val_perc)\n",
    "    data[\"test%\"].append(test_perc)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
