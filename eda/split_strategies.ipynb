{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from config import (\n",
    "    INT_FILTERED_DATA_PATH,\n",
    "    TRANSFORMED_DATA_PATH,\n",
    "    MIN_PLAYS_PER_USER,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to investigate different train-test split strategies.  \n",
    "\n",
    "NB! The notebook was written before including the global user split in the filtering script why the summary statistics are not accurate for the currently used data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "transformed_df = pd.read_parquet(\"../\" + TRANSFORMED_DATA_PATH)\n",
    "int_filtered_df = pd.read_parquet(\"../\" + INT_FILTERED_DATA_PATH)\n",
    "\n",
    "# summary statistics\n",
    "n_users = len(int_filtered_df[\"user_id\"].unique())\n",
    "n_interactions = len(int_filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal User Split\n",
    "\n",
    "This splitting strategy defines a training and test set of each user according to some splitting percentage, e.g., 80% training data and 20% testing data is being recommended in the literature.  \n",
    "\n",
    "Investigating the consequences of implementing a 80-20 split implying that a user should have a total of at least 3 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with at least 3 prd_numbers: 96286 (66.8% of users are kept)\n",
      "Number of interactions left: 2919846 (97.8% of interactions are kept)\n"
     ]
    }
   ],
   "source": [
    "int_filtered_df = pd.read_parquet(\"../\" + INT_FILTERED_DATA_PATH)\n",
    "n_users = len(int_filtered_df[\"user_id\"].unique())\n",
    "n_interactions = len(int_filtered_df)\n",
    "# grouping by user_id and counting the number of prd_numbers for each user\n",
    "df_grouped = int_filtered_df.groupby('user_id')['prd_number'].count().reset_index()\n",
    "df_grouped.rename(columns={'prd_number': 'prd_count'}, inplace=True)\n",
    "\n",
    "# number of users with at least 3 prd_numbers\n",
    "df_grouped = df_grouped[df_grouped['prd_count'] >= 3]\n",
    "\n",
    "# number of users left\n",
    "users_set = set(df_grouped['user_id'])\n",
    "n_users_usplit = len(users_set)\n",
    "\n",
    "# number of interactions left (rows in the df_grouped)\n",
    "df_filtered = int_filtered_df[int_filtered_df['user_id'].isin(users_set)]\n",
    "n_interactions_usplit = len(df_filtered)\n",
    "\n",
    "# printing the results\n",
    "print(f\"Number of users with at least 3 prd_numbers: {n_users_usplit} ({n_users_usplit/n_users:.1%} of users are kept)\")\n",
    "print(f\"Number of interactions left: {n_interactions_usplit} ({n_interactions_usplit/n_interactions:.1%} of interactions are kept)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Global Split\n",
    "Defines two global timestamp that works as the boundary between the train and validation data as well as between the validation and test data for all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make the cuts on the `date` attribute, where the selected date is a Monday. In this way entire weeks are contained in the training and test data. This might be an appropriate decision since podcast listening and publication have weekly patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the proportion between the training, validation, and test data for various split dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train_val_date val_test_date  val_test_weeks     train%       val%  \\\n",
      "0     2024-09-23    2024-10-28               5  24.612396  38.272929   \n",
      "1     2024-10-07    2024-11-04               4  38.615077  31.152292   \n",
      "2     2024-10-21    2024-11-11               3  51.918967  24.572539   \n",
      "3     2024-11-04    2024-11-18               2  66.724009  16.707840   \n",
      "\n",
      "       test%     %users  %interactions  \n",
      "0  37.114675  27.823714      75.685220  \n",
      "1  30.232631  30.400100      78.821276  \n",
      "2  23.508494  30.552142      79.256457  \n",
      "3  16.568151  28.156957      76.462709  \n"
     ]
    }
   ],
   "source": [
    "train_val_split_dates = [\"2024-09-23 00:00:00\", \"2024-10-07 00:00:00\", \"2024-10-21 00:00:00\", \"2024-11-04 00:00:00\"]\n",
    "val_test_split_dates = [\"2024-10-28 00:00:00\", \"2024-11-04 00:00:00\", \"2024-11-11 00:00:00\", \"2024-11-18 00:00:00\"]\n",
    "\n",
    "# data to store data\n",
    "data = {\"train_val_date\": [\"2024-09-23\", \"2024-10-07\", \"2024-10-21\", \"2024-11-04\"],\n",
    "        \"val_test_date\": ['2024-10-28', '2024-11-04', '2024-11-11', '2024-11-18'],\n",
    "        \"val_test_weeks\": [5, 4, 3, 2],\n",
    "        \"train%\": [],\n",
    "        \"val%\": [],\n",
    "        \"test%\": [],\n",
    "        \"%users\": [],\n",
    "        \"%interactions\": []}\n",
    "\n",
    "for date1, date2 in zip(train_val_split_dates, val_test_split_dates):\n",
    "    train_df = int_filtered_df[int_filtered_df[\"date_time\"] < date1]\n",
    "    val_df = int_filtered_df[(int_filtered_df[\"date_time\"] >= date1) & (int_filtered_df[\"date_time\"] < date2)]\n",
    "    test_df = int_filtered_df[int_filtered_df[\"date_time\"] >= date2]\n",
    "\n",
    "    # filtering away users below threshold for number of plays per user\n",
    "    grp_train_users = train_df.groupby('user_id')['prd_number'].count()\n",
    "    filtered_train_df = train_df[train_df['user_id']\n",
    "                                 .isin(grp_train_users[grp_train_users >= MIN_PLAYS_PER_USER].index)]\n",
    "    \n",
    "    # common users across the three sets\n",
    "    train_users = set(filtered_train_df[\"user_id\"])\n",
    "    val_users = set(val_df[\"user_id\"])\n",
    "    test_users = set(test_df[\"user_id\"])\n",
    "    common_users = train_users.intersection(val_users, test_users)\n",
    "    n_common_users = len(common_users)\n",
    "\n",
    "    # filtering the three dataframes according to the common users\n",
    "    train_df = train_df[train_df[\"user_id\"].isin(common_users)]\n",
    "    val_df = val_df[val_df[\"user_id\"].isin(common_users)]\n",
    "    test_df = test_df[test_df[\"user_id\"].isin(common_users)]\n",
    "\n",
    "    # number of interactions in each of the three sets\n",
    "    train_interactions = len(train_df)\n",
    "    val_interactions = len(val_df)\n",
    "    test_interactions = len(test_df)\n",
    "    total_interactions = train_interactions + val_interactions + test_interactions\n",
    "\n",
    "    # proportions\n",
    "    train_perc = train_interactions / total_interactions * 100\n",
    "    val_perc = val_interactions / total_interactions * 100\n",
    "    test_perc = test_interactions / total_interactions * 100\n",
    "    user_perc = n_common_users / n_users * 100\n",
    "    int_perc = total_interactions / n_interactions * 100\n",
    "\n",
    "    # saving to data dict\n",
    "    data[\"train%\"].append(train_perc)\n",
    "    data[\"val%\"].append(val_perc)\n",
    "    data[\"test%\"].append(test_perc)\n",
    "    data[\"%users\"].append(user_perc)\n",
    "    data[\"%interactions\"].append(int_perc)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr-podcast-recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
