{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to investigate different train-test split strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prd_number",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "series_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unique_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "device_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pub_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "episode_duration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "branding_channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mother_channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content_time_spent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "completion_rate",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "accf29a8-7e20-4f8c-92fe-4ec077419416",
       "rows": [
        [
         "0",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11032421443",
         "Brinkmanns briks",
         "Brinkmanns briks: Vi skal tale om pillerne_11032421443",
         "web",
         "PC",
         "2024-10-30",
         "3422",
         "Fakta og debat",
         "DR P1",
         "DR P1",
         "Oplysning og kultur",
         "3423",
         "2024-11-01",
         "08:56:00",
         "1.0"
        ],
        [
         "1",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11032422442",
         "Hjernekassen på P1",
         "Hjernekassen på P1: Forebyggelse_11032422442",
         "web",
         "PC",
         "2024-10-29",
         "3363",
         "Fakta og debat",
         "DR P1",
         "DR P1",
         "Oplysning og kultur",
         "359",
         "2024-11-01",
         "11:19:00",
         "0.10674992566161165"
        ],
        [
         "2",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11162405447",
         "Ubegribeligt",
         "Ubegribeligt: Vand_11162405447",
         "web",
         "PC",
         "2024-10-31",
         "3417",
         "Fakta og debat",
         "DR P1",
         "DR P1",
         "Aktualitet og debat",
         "5160",
         "2024-11-01",
         "09:53:00",
         "1.0"
        ],
        [
         "3",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11802437044",
         "Stjerner og striber",
         "Stjerner og striber: Joken, der ikke vil dø_11802437044",
         "web",
         "PC",
         "2024-11-01",
         "2847",
         "Aktualitet",
         "DR P1",
         "-",
         "Nyheder",
         "2847",
         "2024-11-01",
         "08:40:00",
         "1.0"
        ],
        [
         "4",
         "000065a7ec329b0fc01a779ead0e8d38d987b070300113baba4a120437b07858",
         "11802451178",
         "Tiden",
         "Tiden: Skraldemanden Trump, spansk oversvømmelse og ben-erstatninger_11802451178",
         "web",
         "PC",
         "2024-11-01",
         "947",
         "Nyheder",
         "DR Lyd",
         "-",
         "Nyheder",
         "610",
         "2024-11-01",
         "09:27:00",
         "0.6441393875395988"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prd_number</th>\n",
       "      <th>series_title</th>\n",
       "      <th>unique_title</th>\n",
       "      <th>platform</th>\n",
       "      <th>device_type</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>episode_duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>branding_channel</th>\n",
       "      <th>mother_channel</th>\n",
       "      <th>category</th>\n",
       "      <th>content_time_spent</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>completion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11032421443</td>\n",
       "      <td>Brinkmanns briks</td>\n",
       "      <td>Brinkmanns briks: Vi skal tale om pillerne_110...</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>3422</td>\n",
       "      <td>Fakta og debat</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>Oplysning og kultur</td>\n",
       "      <td>3423</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11032422442</td>\n",
       "      <td>Hjernekassen på P1</td>\n",
       "      <td>Hjernekassen på P1: Forebyggelse_11032422442</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-10-29</td>\n",
       "      <td>3363</td>\n",
       "      <td>Fakta og debat</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>Oplysning og kultur</td>\n",
       "      <td>359</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>11:19:00</td>\n",
       "      <td>0.106750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11162405447</td>\n",
       "      <td>Ubegribeligt</td>\n",
       "      <td>Ubegribeligt: Vand_11162405447</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>3417</td>\n",
       "      <td>Fakta og debat</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>Aktualitet og debat</td>\n",
       "      <td>5160</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>09:53:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11802437044</td>\n",
       "      <td>Stjerner og striber</td>\n",
       "      <td>Stjerner og striber: Joken, der ikke vil dø_11...</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>2847</td>\n",
       "      <td>Aktualitet</td>\n",
       "      <td>DR P1</td>\n",
       "      <td>-</td>\n",
       "      <td>Nyheder</td>\n",
       "      <td>2847</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>08:40:00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000065a7ec329b0fc01a779ead0e8d38d987b070300113...</td>\n",
       "      <td>11802451178</td>\n",
       "      <td>Tiden</td>\n",
       "      <td>Tiden: Skraldemanden Trump, spansk oversvømmel...</td>\n",
       "      <td>web</td>\n",
       "      <td>PC</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>947</td>\n",
       "      <td>Nyheder</td>\n",
       "      <td>DR Lyd</td>\n",
       "      <td>-</td>\n",
       "      <td>Nyheder</td>\n",
       "      <td>610</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>09:27:00</td>\n",
       "      <td>0.644139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_id   prd_number  \\\n",
       "0  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11032421443   \n",
       "1  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11032422442   \n",
       "2  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11162405447   \n",
       "3  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11802437044   \n",
       "4  000065a7ec329b0fc01a779ead0e8d38d987b070300113...  11802451178   \n",
       "\n",
       "          series_title                                       unique_title  \\\n",
       "0     Brinkmanns briks  Brinkmanns briks: Vi skal tale om pillerne_110...   \n",
       "1   Hjernekassen på P1       Hjernekassen på P1: Forebyggelse_11032422442   \n",
       "2         Ubegribeligt                     Ubegribeligt: Vand_11162405447   \n",
       "3  Stjerner og striber  Stjerner og striber: Joken, der ikke vil dø_11...   \n",
       "4                Tiden  Tiden: Skraldemanden Trump, spansk oversvømmel...   \n",
       "\n",
       "  platform device_type    pub_date  episode_duration           genre  \\\n",
       "0      web          PC  2024-10-30              3422  Fakta og debat   \n",
       "1      web          PC  2024-10-29              3363  Fakta og debat   \n",
       "2      web          PC  2024-10-31              3417  Fakta og debat   \n",
       "3      web          PC  2024-11-01              2847      Aktualitet   \n",
       "4      web          PC  2024-11-01               947         Nyheder   \n",
       "\n",
       "  branding_channel mother_channel             category  content_time_spent  \\\n",
       "0            DR P1          DR P1  Oplysning og kultur                3423   \n",
       "1            DR P1          DR P1  Oplysning og kultur                 359   \n",
       "2            DR P1          DR P1  Aktualitet og debat                5160   \n",
       "3            DR P1              -              Nyheder                2847   \n",
       "4           DR Lyd              -              Nyheder                 610   \n",
       "\n",
       "         date      time  completion_rate  \n",
       "0  2024-11-01  08:56:00         1.000000  \n",
       "1  2024-11-01  11:19:00         0.106750  \n",
       "2  2024-11-01  09:53:00         1.000000  \n",
       "3  2024-11-01  08:40:00         1.000000  \n",
       "4  2024-11-01  09:27:00         0.644139  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading transformed data\n",
    "df = pd.read_parquet('../data/podcast_data_transformed.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 142344\n",
      "Number of interactions: 2951510\n"
     ]
    }
   ],
   "source": [
    "# grouping by prd_number and counting the number of plays for each episode\n",
    "prd_grp_df = df.groupby('prd_number')['user_id'].count().sort_values(ascending=True)\n",
    "\n",
    "# filtering away episodes with less than 5 interactions\n",
    "filtered_df = df[df['prd_number'].isin(prd_grp_df[prd_grp_df >= 10].index)]\n",
    "\n",
    "# number of unique users \n",
    "n_users = len(set(filtered_df['user_id']))\n",
    "\n",
    "# number of interactions (rows in the df)\n",
    "n_interactions = len(filtered_df)\n",
    "\n",
    "# printing the summary statistics\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of interactions: {n_interactions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal User Split\n",
    "\n",
    "This splitting strategy defines a training and test set of each user according to some splitting percentage, e.g., 80% training data and 20% testing data is being recommended in the literature.  \n",
    "\n",
    "Investigating the consequences of implementing a 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with at least 3 prd_numbers: 95395 (67.0% of users are kept)\n",
      "Number of interactions left: 2887658 (97.8% of interactions are kept)\n"
     ]
    }
   ],
   "source": [
    "# grouping by user_id and counting the number of prd_numbers for each user\n",
    "df_grouped = filtered_df.groupby('user_id')['prd_number'].count().reset_index()\n",
    "df_grouped.rename(columns={'prd_number': 'prd_count'}, inplace=True)\n",
    "\n",
    "# number of users with at least 3 prd_numbers\n",
    "df_grouped = df_grouped[df_grouped['prd_count'] >= 3]\n",
    "\n",
    "# number of users left\n",
    "users_set = set(df_grouped['user_id'])\n",
    "n_users_usplit = len(users_set)\n",
    "\n",
    "# number of interactions left (rows in the df_grouped)\n",
    "df_filtered = filtered_df[filtered_df['user_id'].isin(users_set)]\n",
    "n_interactions_usplit = len(df_filtered)\n",
    "\n",
    "# printing the results\n",
    "print(f\"Number of users with at least 3 prd_numbers: {n_users_usplit} ({n_users_usplit/n_users:.1%} of users are kept)\")\n",
    "print(f\"Number of interactions left: {n_interactions_usplit} ({n_interactions_usplit/n_interactions:.1%} of interactions are kept)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Global Split\n",
    "Define a single global timestamp that works as the boundary between train and test data for all users/interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make the cut on the `date` attribute, where the selected date is a Monday. In this way entire weeks are contained in the training and test data. This might be an appropriate decision since podcast listening and publication have weekly patterns. This must be investigated in the EDA and related work section about podcast listening patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    train%     test%    users%  interactions%\n",
      "0  2024-10-28  0.603096  0.396904  0.459640       0.880902\n",
      "1  2024-11-04  0.675683  0.324317  0.449313       0.873870\n",
      "2  2024-11-11  0.747187  0.252813  0.426621       0.858558\n",
      "3  2024-11-18  0.821092  0.178908  0.386992       0.825525\n"
     ]
    }
   ],
   "source": [
    "# testing size of train - and test data when splitting on different dates\n",
    "split_dates = ['2024-10-28', '2024-11-04', '2024-11-11', '2024-11-18']\n",
    "\n",
    "data = {'date': split_dates,\n",
    "        'train%': [],\n",
    "        'test%': [],\n",
    "        'users%': [],\n",
    "        'interactions%': [],\n",
    "        }\n",
    "\n",
    "for split_date in split_dates:\n",
    "    # splitting the data\n",
    "    train_df = filtered_df[filtered_df['date'] < split_date]\n",
    "    test_df = filtered_df[filtered_df['date'] >= split_date]\n",
    "\n",
    "    # number of unique users both in the train and test data\n",
    "    common_users = set(train_df['user_id']).intersection(set(test_df['user_id']))\n",
    "    n_common_users = len(common_users)\n",
    "\n",
    "    # filter df according to the common users\n",
    "    train_df_common = train_df[train_df['user_id'].isin(common_users)]\n",
    "    test_df_common = test_df[test_df['user_id'].isin(common_users)]\n",
    "\n",
    "    # computing train and test percentages\n",
    "    train_interactions = len(train_df_common)\n",
    "    test_interactions = len(test_df_common)\n",
    "    total_interactions = train_interactions + test_interactions\n",
    "    train_perc = train_interactions / total_interactions\n",
    "    test_perc = test_interactions / total_interactions\n",
    "    data[\"train%\"].append(train_perc)\n",
    "    data[\"test%\"].append(test_perc)\n",
    "\n",
    "     # computing the percentage of users\n",
    "    perc_users = n_common_users / n_users\n",
    "    data[\"users%\"].append(perc_users)\n",
    "\n",
    "    # computing the percentage of total interactions\n",
    "    perc_interactions = total_interactions / n_interactions\n",
    "    data[\"interactions%\"].append(perc_interactions)\n",
    "\n",
    "# generating a dataframe from the gathered data\n",
    "global_split_df = pd.DataFrame(data)\n",
    "print(global_split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    train%     test%    users%  interactions%\n",
      "0  2024-10-28  0.603076  0.396924  0.454199       0.871050\n",
      "1  2024-11-04  0.675668  0.324332  0.443994       0.864097\n",
      "2  2024-11-11  0.747176  0.252824  0.421571       0.848957\n",
      "3  2024-11-18  0.821085  0.178915  0.382410       0.816293\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "November 11, 2024, seems like a reasonable global split date, as the balance between train and test data is close to 75-25 and more users are kept compared to November 18, 2024.\n",
    "\n",
    "Assessing number of episodes per user in the training set, as I might want to filter away users with less than x episodes for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold    train%     test%  users_total%  users_split%  interactions%\n",
      "0          2  0.998015  0.982172      0.400221      0.938116       0.994010\n",
      "1          3  0.994801  0.965374      0.378843      0.888007       0.987361\n",
      "2          4  0.990688  0.950548      0.360605      0.845258       0.980540\n",
      "3          5  0.985839  0.936243      0.344482      0.807466       0.973301\n"
     ]
    }
   ],
   "source": [
    "# applying global user split\n",
    "split_date = '2024-11-11'\n",
    "train_df = filtered_df[filtered_df['date'] < split_date]\n",
    "test_df = filtered_df[filtered_df['date'] >= split_date]\n",
    "\n",
    "# number of unique users both in the train and test data\n",
    "common_users = set(train_df['user_id']).intersection(set(test_df['user_id']))\n",
    "n_common_users = len(common_users)\n",
    "\n",
    "# filter df according to the common users\n",
    "train_df_common = train_df[train_df['user_id'].isin(common_users)]\n",
    "test_df_common = test_df[test_df['user_id'].isin(common_users)]\n",
    "\n",
    "# number of interactions\n",
    "n_interactions_train = len(train_df_common)\n",
    "n_interactions_test = len(test_df_common)\n",
    "n_interactions_org = n_interactions_train + n_interactions_test\n",
    "\n",
    "# grouping by user_id and counting the number of prd_numbers for each user in the train data\n",
    "df_grouped_train = train_df_common.groupby('user_id')['prd_number'].count().reset_index()\n",
    "\n",
    "# providing a name for the count column\n",
    "df_grouped_train.rename(columns={'prd_number': 'prd_count'}, inplace=True)\n",
    "\n",
    "# thresholds to test\n",
    "user_thresholds = [2, 3, 4, 5]\n",
    "\n",
    "data = {'threshold': user_thresholds,\n",
    "        'train%': [],\n",
    "        'test%': [],\n",
    "        'users_total%': [],\n",
    "        'users_split%': [],\n",
    "        'interactions%': [],\n",
    "        }\n",
    "\n",
    "for threshold in user_thresholds:\n",
    "    # filtering the train data according to the threshold\n",
    "    df_grouped_train_filtered = df_grouped_train[df_grouped_train['prd_count'] >= threshold]\n",
    "    users_set = set(df_grouped_train_filtered['user_id'])\n",
    "    \n",
    "    # filtering the train and test data according to the common users\n",
    "    train_df_common_filtered = train_df_common[train_df_common['user_id'].isin(users_set)]\n",
    "    test_df_common_filtered = test_df_common[test_df_common['user_id'].isin(users_set)]\n",
    "\n",
    "    # computing train and test percentages\n",
    "    train_interactions = len(train_df_common_filtered)\n",
    "    test_interactions = len(test_df_common_filtered)\n",
    "    total_interactions = train_interactions + test_interactions\n",
    "    train_perc = train_interactions / n_interactions_train\n",
    "    test_perc = test_interactions / n_interactions_test\n",
    "    data[\"train%\"].append(train_perc)\n",
    "    data[\"test%\"].append(test_perc)\n",
    "\n",
    "    # computing the percentage of users\n",
    "    perc_users = len(users_set) / n_users\n",
    "    perc_users_split = len(users_set) / n_common_users\n",
    "    data[\"users_total%\"].append(perc_users)\n",
    "    data[\"users_split%\"].append(perc_users_split)\n",
    "\n",
    "    # computing the percentage of total interactions\n",
    "    perc_interactions = total_interactions / n_interactions_org\n",
    "    data[\"interactions%\"].append(perc_interactions)\n",
    "    \n",
    "# generating a dataframe from the gathered data\n",
    "user_split_df = pd.DataFrame(data)\n",
    "print(user_split_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tran%` and `test%` indicate the percentages of the interactions in the original train and test sets before filtering on the number of plays per user.\n",
    "\n",
    "`user_total%` indicate the percentage of original users kept before applying any filtering. This was 42.2% for the global split using 2024-11-11 as the split date.\n",
    "\n",
    "`user_split%`indicate the percentage of users kept after applying the global split, but before filtering on the number of plays per user.\n",
    "\n",
    "`interactions%` indicate the percentage of interactions among both the train and test set before filtering on the number of plays per user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision\n",
    "The user split keeps a larger proportion of the users and interactions, but is a less realistic strategy to implement for the collaborative filtering algorithms. This is because some of the training data will be in the future compared to some of the testing data and vice versa.  \n",
    "\n",
    "The global split throws away more users and a few more interactions. However, it enforces a more realistic splitting strategy, why I'm favoring this strategy over the temporal user split.  \n",
    "\n",
    "For the global user split I'll use 2024-11-11 as the split date and filter on users with at least 2 plays in the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
