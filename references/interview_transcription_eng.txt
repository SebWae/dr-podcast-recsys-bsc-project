 SW: 
 Alright, I'm starting the recording now.

 MJ: 
 Yes. I'm just sitting here thinking about what I should say.

 SW: 
 The first thing I was thinking I’d ask you about is what kind of recommendations there actually are in DR LYD.
 I just tried to take a look myself to see what I could find.
 And as far as I can tell, it’s both recommendations for entire series and also individual episodes
 
 MJ: 
 Yes, so you could say, I can take you through where we use our recommendation system.
 You can start by distinguishing a bit between what a recommendation actually is.
 So, you could say, in relation to some kind of behavior.
 There are things where editors sit and create lists that are static for everyone.
 Those aren’t recommendations in this sense.
 Then there’s, for example, the module that you’ll encounter — the second module, if we’re talking about the app. I'm using the app as the basis here, so if there's something else regarding the web, you’ll have to ask.
 The second module is the behavior-driven one, "Your Shortcuts."
 It’s not really a recommendation system — we built it ourselves — and it's not recommendations in the sense of something algorithmically advanced, but it just looks at your behavior.
 For example, I’m pointing down at the "Your Shortcuts" module, where I’ve previously listened to “Tiden,” the series “Tiden.”
 Then there’s a marker showing that there’s a new episode of “Tiden.”
 That’s also a kind of recommendation — at least it’s an indication that you’ve shown some behavior.
 We want to make you aware that there’s a new episode, and the system does that automatically.
 And then there’s the part about recommendation systems and algorithms.
 We have that in different places.
 The most prominent one is actually fairly hidden.
 So I press the player.
 Then I press the queue.
 And what you see when you're in the queue is that first I’ve started playing an episode — it’s “A Deadly Secret.”
 If I had added something to the queue, it would show up as “next in the queue,” but I haven’t.
 That would be what plays next.
 If you don’t have anything in the queue, the next thing in this autoplay sequence will be:
 If there's a newer episode in the same series I’m currently listening to, that would play next — and in this case, there is.
 If not A (the queue), and not B (a new episode), then we have a recommendation algorithm — a recommendation system — that selects a recommendation for you.
 In this case, it's “A Toxic Consideration,” which is clearly the most used recommendation direction in the DR LYD product.
 It’s an algorithm that doesn’t look at you as a user.
 That’s why we’re allowed to send it to everyone — it doesn’t require consent for preferences, because it’s not based on your consumption or taste profile.
 It looks at other users instead.
 So it says: “Other users who listen to ‘A Deadly Secret,’ what do they prefer most?”
 And then we serve that as a recommendation.
 So it links the content start to other users, not to you.
 That’s what we call a collaborative filtering algorithm.
 And you could say, that’s one of those algorithmic recommendation systems.
 That’s one type/school of recommendations — where you connect content with other users.
 
 SW: 
 Is it solely based on the episode you're listening to right now?
 
 MJ: 
 Yes, so when it generates — you can play around with it yourself.
 So if I click on “A Toxic Consideration” here...
 Yes, and because I haven’t played anything yet — let’s just see if we can...
 So if we go ahead and start “Chris and the Chocolate Factory” here, then it actually recommends “Korfix and Coffee.”
 And then it recommends “Snooze” again.
 And then it recommends, and so on.
 
 SW: 
 So you get a whole chain?

 MJ: 
 Yes.
 So it's always based on what’s new in relation to the users who are listening — what else are they listening to the most?
 So it’s a popularity algorithm.
 And the reason we use it in an autoplay setup is that it’s an invisible recommendation, which starts automatically, and that’s why we try to aim for something that is relatively safe or popular.
 That, all things considered, gives us a fairly good recommendation — even if it’s not the most spot-on.
 In many cases, it will be, but you can also end up in the corners of our catalog, where there might not be that many listeners.
 And then, all things being equal, it will also be more...
 It’s clear: the fewer users who listen to something, the fewer there are to ask what else they listen to.
 And then the recommendation will be less robust.
 So naturally, when we look at some of our really big titles — "Sara & Monopolet", "Genstart", "Tyran", etc. — we can be fairly certain that we’re capturing roughly what other people are also listening to.
 That’s why we typically get some pretty solid recommendations.
 We can try starting an episode of "Tyran".
 Then we get "Ministermord".
 "Tyran" is about some nasty guys who ruled countries with a heavy hand, and here you then get a historical podcast about the murder of John F. Kennedy.
 That’s actually a pretty solid recommendation, you could say.
 So that’s one of the recommendations we’re quite happy with — and it’s like that with most of them.
 So I would highlight that as a very significant and important recommendation — which ideally should feel very seamless and compelling.
 In many ways, it actually mimics what’s called “flow” in live radio — like when a radio channel transitions you from one program to another.
 If you’re on P1, you start with one program, and it automatically sends you into the next, just because you’re still listening to P1.
 Here, we do the same, but uniquely for each title — so it’s just a much more advanced and sophisticated kind of channel curation, you might say.
 It basically becomes your own personal channel, with thousands of variations, depending on which programs you choose to include.
 
 SW: 
 Will it always recommend the newest episode?
 
 MJ:
 Yes.
 
 SW: 
 Of the most popular show?
 
 MJ: 
 Yes.
 Uh…
 If it’s closed series, like “Tyran”, where it’s a closed narrative, then — because of how the feeds are structured — in “Tyran” you would always start with episode 1.
 Always.
 Of the newest season.
 Because you’d have a poor experience if you were dropped into episode 3.
 So we try to make sure, as much as possible, that you don’t enter a story that’s already in progress.
 I want it to start from the right end.
 But for ongoing formats like “Sara & Monopolet” and “Genstart”, it’s always the newest episode, because it doesn’t depend on whether you’ve listened to anything previously.
 I can also say: if you go into a series page — you do that by clicking on an item like this — now I’m on a series page, and there’s a tab next to “Episodes” called “Recommendations.”
 If I click there, I get a row of related recommendations.
 That one also isn’t user-specific.
 Or rather — it’s not user-specific at all.
 The other one was based on other users.
 This one links content to other content.
 So it’s purely metadata.
 It’s old-fashioned tagging, really — like we know it from websites.
 If you click on this, these are the things it has been tagged with.
 So it’s tagged in various ways.
 But ideally, that should help ensure that the content you see — the content page you’re on and the main series page you’ve landed on — the content should make sense in relation to that.
 So I’m in a scenario where maybe I’ve landed on a series page, and oh — there are no new episodes in the series I just listened to.
 What can I do in the meantime?
 It could be consuming something similar.
 And that’s what we try to present here.
 And because it’s content-to-content, we can show it to all users.
 That also doesn’t require consent for preferences, because it’s just content pointing to content.
 So it’s classic top-level tagging.
 
 SW: 
 It will look the same for all users?
 
 MJ: 
 Yes, and it’s also not dynamic.
 If we look at something that is dynamic, you can scroll down to the row called “Recommended for you.”
 That will only be shown if you haven’t declined preference settings.
 So this “Recommended for you” row will appear only if you’ve agreed to preferences.
 It’s generated from our recommendation system, which identifies you as someone who wants recommendations and therefore hasn’t opted out of preference consent.
 We then create a taste profile, where each series has various tags with different weights, which contribute to that profile.
 So, for example, if I listen to an episode of “Tyran,” there will be certain weights or features.
 It could be about World War II, history, dictators — something like that.
 It’s all tagged.
 Then there’s a feature hierarchy, where the rule of thumb is: the more specific, the higher the weight.
 So World War II is more specific than history, meaning it gets a higher weight.
 That means it’s added to your taste profile, which is meant to be in constant, organic development — ideally evolving along with you.
 So if you suddenly stop listening to history podcasts and start listening more to lifestyle content, your taste profile will gradually shift to favor those kinds of weighted features.
 And then recommendations will be made based on that.
 This is an example of a recommendation that requires consent, because it looks at you and your behavior over time.
 It also puts more emphasis on your recent listens, and over time, older listens will lose influence in shaping your taste profile.
 So the system is always trying to determine what’s relevant for you right now.
 We don’t keep showing Christmas content just because you loved it back in December — it’s meant to feel relevant.
 Those are the three main types of recommendations behind our system.
 There are gradations of each, of course, but these are the three basic approaches:
 The related one, which links content to other content.
 The collaborative one, which links content based on what other users listen to.
 And the personalized one, which looks at your behavior and links that to content.
 So those are the three fundamental types of recommendations.
 
 SW: 
 The last one you mentioned, “Recommended for you” — will it also recommend current series that have released new episodes?
 
 MJ: 
 Yes, it actually doesn’t really care — I mean, you could say, the reason we use such a system is that, with media development, we've moved away from sitting in front of desktop computers where there’s lots of space to display content.
 Now we’re dealing with smaller and smaller screens, so in a way, it’s about functioning as a display window.
 But obviously, with smaller “shops,” there’s also room for fewer “products.”
 So we have to be creative with how we use that space.
 And if we didn’t have these systems, we’d often just end up showcasing the biggest series — because those are relevant to the most people — and we’d plaster that all over the place.
 It would all be big and popular content.
 And that goes against what public service is about.
 Public service is also about challenging you with content you didn’t know existed — or that isn’t the most popular.
 Also content from our archive.
 What we’re doing is creating a better match between you and the most relevant content — regardless of when it was made.
 Quality control is still in place — because it’s still published, and publishing editors ensure it’s still good content.
 Even if it was made three years ago.
 So this is a way for a documentary from three years ago to reach you as a user.
 Which would otherwise be very difficult in such a huge catalog — especially if you don’t even know what you’re looking for.
 So this is one of the ways to make use of the limited space we have —
 By saying: this recommendation is actually unique to the individual.
 We make sure to bring forward content from the archive that’s relevant to you.
 
 SW: 
 So would you say that each visible recommendation serves its own purpose?
 
 MJ: 
 Yes, absolutely.
 We choose based on what the need is in that context.
 You can go back to the point about the autoplay recommendation — where commercial actors like Spotify use an algorithm that’s heavily based on your habits.
 They use something called a “don’t miss” algorithm, which plays content you’re already engaging with.
 And that’s probably a really good idea, but it also means the user’s horizon isn’t being expanded through that method.
 We do use a popularity algorithm, but it’s still one that doesn’t look at what you’re already consuming.
 If you look away from that and say, “we don’t need to deal with what’s already been discovered,” then we actually want to use this opportunity to show you something new we think you might be interested in.
 That way, we also get a large part of the catalog circulated through such a list.
 And in that sense, an algorithm helps fulfill a public service mission.
 And just to say — recommendation systems can be used in a commercial context, where the goal is pure retention, and in a public service context, where the goal is also discovery and broadening the content offering by trying to present new material.
 So it just shows that these systems can be used in different ways for different purposes.
 
 SW: 
 Does that mean the public service aspect is more important than making the recommendations highly personalized?
 
 MJ: 
 I don’t know if it’s either-or, but it’s clear that we have to ask ourselves: why do we have DR LYD when Spotify and Apple exist?
 We have to be able to offer something different.
 And also have a real intent toward you as a user — not just leave you entirely to yourself.
 That’s why we have a much more active curation — that’s the other side of the coin.
 It’s not just recommendation systems — far from it.
 The majority of DR LYD — and this is important to mention when talking about the different recommendation systems — is made up of real people and editors. I’m one of those who manage and organize them to meet the needs and goals we have.
 And in fact, most of the presentation layer within DR LYD is fully curated, where people have chosen what to highlight.
 So it’s a mix, but clearly, the freedom DR has by not needing paying customers also carries an obligation to do things differently than the commercial players
 
 SW: 
 What’s the definition of "Selected Favorites" — are those series chosen by editors? 
 
 MJ: 
 It’s a composite module.
 It works like this: it’s an automated top list combined with a curated selection.
 So it’s actually a... well, both parts are... that is, none of it is what you’d call machine-generated recommendations, but one part is generated automatically and simply looks at pure play counts.
 So it’s a list that’s a mix of what’s very popular right now — to reflect the idea that we also want content that Danes can gather around and share as a common experience.
 There are some common titles we look at.
 But there are also some that we push editorially — where it might be the next title we want people to gather around.
 That’s why we’ve chosen or produced it — to see if it can become big.
 Because we believe it has the potential.
 So those are the two needs at play here.
 
 SW: 
 I think I’m also a bit more curious about how recommendations compare one series to another.
 You mentioned something about tagging?
 Is that done manually or automatically? 
 
 MJ: 
 It is primarily done quite manually.
 We have a data management team at Danmarks Radio who look at a new title when it is submitted.
 They sit and examine it, whether it’s an episode or a series, but if we start with a new series, they look at the title, the image, and read the description themselves.
 They also listen to some of it.
 Based on that, they have a tagging system with standardized tags, so there is consistency to things we can find in the others, where they attach keywords, as well as a main genre and a subgenre, and this is then transferred to our recommendation system.
 That’s where the calculation, so to speak, happens in the background.
 So it could easily be, in the future, that some of this could be automated more.
 One could certainly imagine that this is what others do.
 For example, transcribing an audio file, and from there, I find relevant keywords that I can tag.
 We’re not there yet.
 I’m not sure if we should be.
 So at Danmarks Radio, it’s live humans who quality check and manually do this up-tagging, which is then added to the recommendation system, which then translates it into the system that does the math to ultimately decide which article or content should be recommended.
 
 SW: 
 Okay.
 I’m thinking right now that this might be something I could investigate.
 I plan to create a recommendation system based on transcriptions.
 If I can get the transcriptions out.
 
 MJ: 
 Yes, there is a team at DR working on that.
 I can certainly put you in touch with the people who manage that process. 
 
 SW: 
 Yes, the people who create the transcriptions?
 
 MJ: 
 Yes, and the people who have done the experiments behind it. 
 
 SW: 
 I know I can retrieve them manually from Mediarkiet, but I now have data for 3 months, and there have been listens to something like 20,000 different episodes, and I can’t go in and manually download so many episodes.
 
 MJ: 
 No, that’s probably not practical for that.
 But there are two different teams that have done experiments regarding those transcriptions and creating keywords.
 I can definitely put you in touch with them.
 
 SW: 
 I can imagine there’s a gain from it, but I don’t know if it’s big enough because it really requires something extra to find a keyword in an automated way.
 
 MJ: 
 Well, what I know is that one of the challenges is that AI is constantly getting smarter and better, so it’s a development that’s moving in one direction, as it looks right now.
 But right now, when we test, they can have difficulty weighing what is really important in the text.
 They can generate some words, but Lars Løkke might be mentioned in a subordinate clause, but it’s not a dominant topic for the series.
 I’ve mentioned the name quickly three times, but it’s still not important for what’s actually being discussed.
 So you can quickly get a bias that shouldn’t be there.
 So, getting them to do the right weighting, I think, is still a challenge.
 There are also other attempts to turn the transcription into text.
 And based on that text, you can manually label it.
 And that’s also a language where you could say you’re halfway there.
 Because it might be a different type of text than what might be needed.
 I mean, the texts that are much more based on today are ones that are written elaborately.
 A series description that’s supposed to make the user decide whether they want to listen to the content or not.
 It’s not certain that the same text is just as good for a data labeling specialist to label the content in the best possible way.
 They might be two different texts.
 So that could be the issue.
 I know that can also be tested. 
 
 SW: 
 Yes.
 Let’s just see what other questions I have now.
 Yes, where we…
 All the recommendation algorithms, are they ones we’ve developed ourselves, or are they ones we get from external sources?
 
 MJ: 
 It’s a third-party external provider.
 Currently, there are no plans to do it ourselves.
 It’s always a trade-off.
 In other Nordic countries, they have worked on it themselves.
 It might have worked, but the downside is that it can take a long time to get started.
 We have a pretty good level of recommendations.
 The downside, of course, is that it can be harder to make changes or test adjustments because we don’t own the interfaces ourselves.
 We can’t determine how it’s expressed ourselves.
 It’s obviously a dialogue we have.
 We get the development done tailored to us.
 So, it’s also about whether we should have specialists who can create these types of systems ourselves or if it’s better to buy the service from specialists.
 But right now, it’s a third-party system.
 
 SW: 
 But you have a lot of influence over how you want it to look?
 
 MJ: 
 Yes, we have ongoing development time, and we are the ones who decide how we use the system and how it interacts with our users.
 So, in that sense, we have full control, but of course, we own the data we share with them.
 We also own the metadata translations that happen through them.
 So, in that way, if we decide to do something else someday, we can take it further.
 So, in that sense, the value chain is secured.
 So, that’s it.
 
 SW: 
 I think the last question is how the recommendation algorithm is affected by mandatory login and whether it's possible to imagine having a user profile across platforms, where we look at what you do on DRTV and dr.dk?
 
 MJ: 
 Definitely, I mean, right now, mandatory login only applies on TV.
 And our recommendation system and data still don’t communicate across platforms.
 But the perspective is correct, what you’re saying.
 I mean, right now, one of the big advantages of login for users is that we currently deliver a siloed experience for the user.
 That is, in DR LYD, we do the best for those who are currently in DR LYD.
 In DRTV, they do the best for those who are currently in DRTV, and on dr.dk, they do the best for those who are currently on dr.dk.
 We don’t really think across platforms.
 But that’s the way life is right now.
 I myself listen to the radio in the morning, browse a bit while I’m on the toilet at work, and then watch the news on TV in the evening.
 So, that’s kind of how a person’s life looks.
 And therefore, you could say that our recommendations today are handicapped because we can only see you in one of those usage situations.
 So, you could say that learning more about you as a complete user would also allow us to offer you a much better experience.
 Because it could mean that you prefer to only listen to current affairs.
 On LYD, when you started with DRTV watching a film, and then I don’t think the DRTV system necessarily believes you’re interested in current affairs.
 But if we had the knowledge that you’re actually a big consumer of those topics, we could bring something interesting for you on DRTV as well.
 So, there are some perspectives here on cross-platforms, which are incredibly complex across systems and user behavior.
 It’s clear that dr.dk and DR LYD have in common that they’re very much something you do alone, whereas DRTV is something you do with others.
 So, what does it mean when "Gurli Gris" is put on at home?
 Then there are child profiles, etc.
 But it can be incredibly difficult, there are many challenges to solve.
 Therefore, it’s actually that we can be as relevant as possible for the users.
 But the perspective is probably that we can…
 Now DR LYD is the little sister in the group of the three digital DR products.
 There can easily be users who are extremely interested in, for example, a documentary about the Indonesian genocide in the 20th century, which was covered in the documentary The Act of Killing, which was available on DRTV, and there has been a Tyran season about that dictator.
 It’s not certain that the person who watched that documentary knows that it exists on DR LYD.
 But it’s very relevant because it’s a perspective that suggests we can link those things together.
 And give them the information that we’re showcasing it here.
 
 SW: 
 That would be great.
 
 MJ: 
 But there's a bit of work ahead.
 
 SW: 
 That’s for sure.
 I also don’t know if you could just say what you do on a daily basis.
 I was referred to you by Mads, so I don’t know much about what you do.
 
 MJ: 
 Yes, yes.
 So, you could say that I’m a development editor at DR LYD publishing.
 This means that in some parts of my work, I act as a link between technology, development, user needs, and the more journalistic, editorial side.
 So, I try to be the connection between, okay, there’s a technological recommendation, some opportunities here.
 How do we translate that into what we want to do with it editorially?
 It’s a lot about me and my colleagues, who set the needs down to technology, what do we want to achieve?
 And then we try to work together to formulate some solutions for how we can get there, so we can do that for the users.
 So in relation to some of the LYD cases I’ve described, e.g., the autoplay, we need this recommendation to behave in this and this way to help us achieve that.
 So that’s some of what I do.
 
 SW: 
 Well, then I’ve spoken to the right person.
 
 MJ: 
 Yes, that's good!
 
 SW: 
 I think that was everything I wanted to ask you about. 
 
 MJ: 
 That's great, Sebastian.
 Otherwise, you have my email, so just write if there’s anything you want clarified or if there’s something you're unsure about.
 Yes, you're welcome to write anytime.
 
 SW: 
 And it’s totally fine if I save the recording.
 
 MJ: 
 Yes, yes, as long as you use it for the task.
 If you use it for something else, of course, you can ask me about it.
 But if it’s for the task, then it’s absolutely fine.
 
 SW: 
 I don’t plan to.
 Thanks for your time.